{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dafa5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import time\n",
    "from cv2 import findHomography\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import scipy.io as io\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49ca306",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f1ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings['dataset'] = 'kitti' # choose from ['kitti', 'carla']\n",
    "settings[\"patch_size\"] = 9 #7\n",
    "\n",
    "if settings['dataset']=='kitti':\n",
    "    settings[\"data_path\"] = './data/kitti'\n",
    "else:\n",
    "    settings[\"data_path\"] = './data/carla'\n",
    "\n",
    "settings[\"results_directory\"] = './results/' + settings['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7357a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'kitti',\n",
       " 'patch_size': 9,\n",
       " 'data_path': './data/kitti',\n",
       " 'results_directory': './results/kitti'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d5820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should down size the images, to see results quickly\n",
    "settings[\"width\"] = 800#512\n",
    "settings[\"height\"] = 600#256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6ee5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of depth proposals\n",
    "settings[\"num_depths\"] = 100\n",
    "settings[\"min_depth\"] =  2.0 # in meters\n",
    "settings[\"max_depth\"] =  20000.0\n",
    "\n",
    "settings[\"similarity\"] = \"SSD\"\n",
    "os.makedirs(settings[\"results_directory\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f91b4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'kitti',\n",
       " 'patch_size': 9,\n",
       " 'data_path': './data/kitti',\n",
       " 'results_directory': './results/kitti',\n",
       " 'width': 800,\n",
       " 'height': 600,\n",
       " 'num_depths': 100,\n",
       " 'min_depth': 2.0,\n",
       " 'max_depth': 20000.0,\n",
       " 'similarity': 'SSD'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1798e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_proposals(min_depth, max_depth, num_depths):\n",
    "    '''\n",
    "    return list of depth proposals\n",
    "    you can sample the range [min_depth, max_depth] uniformly at num_depths points.\n",
    "    Tip: linearly sampling depth range doesnot lead to a linear step along the epipolar line.\n",
    "    Instead, linearly sample the inverse-depth [1/min_depth, 1/max_depth] then take its inverse to get depth values.\n",
    "    This is practically more meaningful as it leads to linear step in pixel space.\n",
    "    '''\n",
    "    depth_proposals_inv = np.linspace(1/min_depth, 1/max_depth, num_depths)\n",
    "    return 1/depth_proposals_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5773f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_file(depth_map, filename):\n",
    "    \"\"\"\n",
    "    Saves depth maps to as images\n",
    "    feel free to modify it, it you want to get fancy pics\n",
    "    \"\"\"\n",
    "    depth_ = 1/(depth_map+0.00001)\n",
    "    depth_ = 255.0*depth_/(np.percentile(depth_.max(), 95))\n",
    "    cv.imwrite(filename, depth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba2691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_make_border(img, patch_width):\n",
    "    \"\"\"\n",
    "    This function applies cv.copyMakeBorder to extend the image by patch_width/2\n",
    "    in top, bottom, left and right part of the image\n",
    "    Patches/windows centered at the border of the image need additional padding of size patch_width/2\n",
    "    \"\"\"\n",
    "    offset = np.int32(patch_width/2.0)\n",
    "    return cv.copyMakeBorder(img,\n",
    "                             top=offset, bottom=offset,\n",
    "                             left=offset, right=offset,\n",
    "                             borderType=cv.BORDER_REFLECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8fa44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pathches(img, patch_width):\n",
    "    '''\n",
    "    Input:\n",
    "        image: size[h,w,3]\n",
    "    Return:\n",
    "        patches: size[h, w, patch_width, patch_width, c]\n",
    "    '''\n",
    "    if img.ndim==3:\n",
    "        h, w, c = img.shape\n",
    "    else:\n",
    "        h, w = img.shape\n",
    "        c = 1\n",
    "    img_padded = copy_make_border(img, patch_width)\n",
    "    patches = image.extract_patches_2d(img_padded, (patch_width, patch_width))\n",
    "    patches = patches.reshape(h, w, patch_width, patch_width, c)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c011ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kitti_calib_file():\n",
    "    filename = os.path.join(settings[\"data_path\"], 'calib.txt')\n",
    "    data = np.fromfile(filename, sep=' ').reshape(3,4)[0:3,0:3]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a93f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_carla_calib_file():\n",
    "    fov=90.0\n",
    "    height=600\n",
    "    width=800\n",
    "    k = np.identity(3)\n",
    "    k[0, 2] = width / 2.0\n",
    "    k[1, 2] = height / 2.0\n",
    "    k[0, 0] = k[1, 1] = width / \\\n",
    "                        (2.0 * math.tan(fov * math.pi / 360.0))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d30032ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs_and_k_mats():\n",
    "    img_0 = cv.imread(os.path.join(settings['data_path'], 'images', '0.png'))\n",
    "    img_h, img_w, c = img_0.shape\n",
    "    # Load and Downsize the images, for faster computation\n",
    "    height, width = settings['height'], settings['width']\n",
    "    imgs = [cv.resize(cv.imread(os.path.join(settings[\"data_path\"], 'images', str(ii)+'.png')),\\\n",
    "    (settings['width'], settings['height']))\\\n",
    "    for ii in range(5)]\n",
    "    source_img = imgs.pop(2)\n",
    "    input_imgs = imgs\n",
    "    if settings['dataset']=='kitti':\n",
    "        k_matrix = read_kitti_calib_file()\n",
    "    else:\n",
    "        k_matrix = read_carla_calib_file()\n",
    "    k_matrix[0,:] = k_matrix[0,:]*float(width)/float(img_w)\n",
    "    k_matrix[1,:] = k_matrix[1,:]*float(height)/float(img_h)\n",
    "    return input_imgs, source_img, k_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d554bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camera_pose():\n",
    "    if settings['dataset']=='kitti':\n",
    "        filename = os.path.join(settings[\"data_path\"], 'cam_pose.txt')\n",
    "        data = np.fromfile(filename, sep=' ').reshape(5, 3,4)\n",
    "        RMats = data[:,0:3,0:3]\n",
    "        TVecs = data[:,:,3]\n",
    "        # We should make the middle view as our source view.\n",
    "        mid = 2\n",
    "        ref_R = RMats[mid]\n",
    "        ref_T = TVecs[mid]\n",
    "        rot_mat_list = []\n",
    "        t_vec_list = []\n",
    "        for ii in range(5):\n",
    "            R, T = RMats[ii], TVecs[ii]\n",
    "            R_ii = np.dot(np.linalg.inv(R), ref_R)\n",
    "            T_ii = np.dot(np.linalg.inv(R), (ref_T-T)).reshape(3,1)\n",
    "            rot_mat_list.append(R_ii)\n",
    "            t_vec_list.append(T_ii)\n",
    "    else:\n",
    "        # This is for carla dataset\n",
    "        # do not change this function\n",
    "        t_vec_list = [np.array([0, 0, (i-2)*0.54], dtype=np.float64).reshape(3,1) for i in range(5)]\n",
    "        rot_mat_list = [np.eye(3) for i in range(5)]\n",
    "    return rot_mat_list, t_vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2df57da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images, K-Matrix and Camera Pose\n",
    "# Except K matric which is 3x3 array, other parameters are lists\n",
    "\n",
    "input_imgs, source_img, k_matrix = load_imgs_and_k_mats()\n",
    "# input_imgs is a list of 4 images while source_img is a single image\n",
    "r_matrices, t_vectors = load_camera_pose()\n",
    "# r_matrices and t_vectors are lists of length 5\n",
    "# values at index 2 are for the middle camera which is the reference camera\n",
    "# print(r_matrices[2]) # identity\n",
    "# print(t_vectors[2]) # zeros\n",
    "# print(k_matrix) # a 3x3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d11cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(feature_1, feature_2):      #from solution exercise 4, modified\n",
    "    '''\n",
    "    inputs: feature_1 and feature_2 with shape[w, h, p, p , 3]\n",
    "    p = patch_width\n",
    "    return: per pixel distance , shape[w, h]\n",
    "    '''\n",
    "    sq_diff = np.square(feature_1 - feature_2).astype('float')\n",
    "    ssd_val = np.sum(sq_diff, axis=(2,3,4))\n",
    "    return ssd_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0faa623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ssd(feature_1, feature_2, feature_3, feature_4):\n",
    "    ssd_val12 = ssd(feature_1, feature_2)\n",
    "    ssd_val13 = ssd(feature_1, feature_3)\n",
    "    ssd_val14 = ssd(feature_1, feature_4)\n",
    "    ssd_val23 = ssd(feature_2, feature_3)\n",
    "    ssd_val24 = ssd(feature_2, feature_4)\n",
    "    ssd_val34 = ssd(feature_3, feature_4)\n",
    "    return (ssd_val12 + ssd_val13 + ssd_val14 + ssd_val23 + ssd_val24 + ssd_val34)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a1d2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHomography(depth, K_inv, P):\n",
    "    '''\n",
    "    inputs:\n",
    "        depth: depth_value (float)\n",
    "        K_inv : Inverses of the camera matrix\n",
    "        P: Projection matrices of the target view\n",
    "    return: Homography, that maps Points with depth depth from the source view to the corresponding possition of the\n",
    "        input view\n",
    "    '''\n",
    "    Corners_hom = np.array([[0,0,1], [settings['height'],0,1], [0,settings['width'],1], [settings['height'],settings['width'],1]])\n",
    "    Corners_3D_depth = depth * np.einsum('pi,ji', Corners_hom, K_inv)\n",
    "    Corners_3d_depth_hom = np.vstack((Corners_3D_depth, np.ones(4))).T\n",
    "    Projec_hom = np.einsum('pi,ji', Corners_3d_depth_hom, P).T\n",
    "    Projec = np.vstack(((Projec_hom.T[0]/Projec_hom.T[2]),(Projec_hom.T[1]/Projec_hom.T[2]))).T\n",
    "    Hom, m = cv.findHomography(Corners_hom[:,:2],Projec)\n",
    "    return Hom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08aa118b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'inshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a28f69a4706d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarp_combined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'inshow'"
     ]
    }
   ],
   "source": [
    "def ssd_merge(ssd_values):\n",
    "    '''\n",
    "    input: ssd_ values: float array containing for each pixel the ssd values for allinput views, shape = (h,w,4)\n",
    "    output: array of for each pixel combined ssd values. shape = (h,w) \n",
    "    '''\n",
    "    return np.mean(ssd_values, axis = 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    patch_size = settings[\"patch_size\"]\n",
    "    num_depths = settings[\"num_depths\"]\n",
    "    min_depth = settings[\"min_depth\"]\n",
    "    max_depth = settings[\"max_depth\"]\n",
    "    Depth_proposals = get_depth_proposals(settings['min_depth'], settings['max_depth'], num_depths=settings['num_depths'])\n",
    "    Patches_source = extract_pathches(source_img, settings['patch_size'])\n",
    "\n",
    "    #Extract Patches\n",
    "    Patches_source = extract_pathches(source_img,settings['patch_size'])\n",
    "    Patches_input = []\n",
    "    for im in input_imgs:\n",
    "        Patches_input.append(extract_pathches(im, patch_size))\n",
    "    Patches_input = np.array(Patches_input)     #has shape (#input cams, width, height)\n",
    "\n",
    "    # Compute projection matrices\n",
    "    P_matrices = []\n",
    "    for i in [0,1,3,4]:\n",
    "        P_mat = k_matrix @ np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]]) @ np.vstack((np.hstack((r_matrices[i], t_vectors[i])), np.array([0,0,0,1])))\n",
    "        P_matrices.append(P_mat)\n",
    "    P_matrices = np.array(P_matrices)\n",
    "    K_inv = np.linalg.inv(k_matrix) \n",
    "     # ___________________________________________Task 1___________________________________________\n",
    "    max_ssd = -1 * np.ones((settings['height'], settings['width']))\n",
    "    Depth_map = np.zeros((settings['height'], settings['width']))\n",
    "    for d in Depth_proposals:\n",
    "        ssd_Scores = np.zeros((settings['height'], settings['width'],4))\n",
    "        for c in range(4):\n",
    "            Input_img = input_imgs[c]\n",
    "            Hom = computeHomography(d, K_inv, P_matrices[c])\n",
    "            WarpedInput = cv.warpPerspective(Input_img, Hom, (settings['width'],settings['height']))\n",
    "            Patches_WarpedInput = extract_pathches(WarpedInput, settings['patch_size'])\n",
    "            ssd_Scores_c = ssd(Patches_source, Patches_WarpedInput)\n",
    "            ssd_Scores[:,:,c] = ssd_Scores_c\n",
    "        ssd_Scores_comb = ssd_merge(ssd_Scores)\n",
    "        ssd_greater = np.greater(ssd_Scores_comb,max_ssd)\n",
    "        max_ssd = np.where(ssd_greater, ssd_Scores_comb, max_ssd)\n",
    "        Depth_map = np.where(ssd_greater, d*np.ones_like(Depth_map), Depth_map)\n",
    "        depth_to_file(Depth_map, './results/'+ settings['dataset'] +'/depthmap'+ \\\n",
    "            str(settings[\"patch_size\"]) + 'x' + str(settings[\"patch_size\"]) + '.jpg')\n",
    "        \n",
    "         # ___________________________________________Task 2___________________________________________\n",
    "    ReconstructCam2 = np.zeros_like(source_img)\n",
    "    ssd_opt = -1*np.ones((settings['height'],settings['width']))\n",
    "    for d in Depth_proposals:\n",
    "        Hom0 = computeHomography(d, K_inv, P_matrices[0])\n",
    "        Hom1 = computeHomography(d, K_inv, P_matrices[1])\n",
    "        Hom3 = computeHomography(d, K_inv, P_matrices[2])\n",
    "        Hom4 = computeHomography(d, K_inv, P_matrices[3])\n",
    "        WarpedCam0 = cv.warpPerspective(input_imgs[0], Hom0, (settings['width'],settings['height']))\n",
    "        WarpedCam1 = cv.warpPerspective(input_imgs[1], Hom1, (settings['width'],settings['height']))\n",
    "        WarpedCam3 = cv.warpPerspective(input_imgs[2], Hom3, (settings['width'],settings['height']))\n",
    "        WarpedCam4 = cv.warpPerspective(input_imgs[3], Hom4, (settings['width'],settings['height']))\n",
    "        Patches_WarpedCam0 = extract_pathches(WarpedCam0, settings['patch_size'])\n",
    "        Patches_WarpedCam1 = extract_pathches(WarpedCam1, settings['patch_size'])\n",
    "        Patches_WarpedCam3 = extract_pathches(WarpedCam3, settings['patch_size'])\n",
    "        Patches_WarpedCam4 = extract_pathches(WarpedCam4, settings['patch_size'])\n",
    "        ssd_Scores = mean_ssd(Patches_WarpedCam0,Patches_WarpedCam1,Patches_WarpedCam3,Patches_WarpedCam4)\n",
    "        warp_combined = np.median(np.array([WarpedCam0, WarpedCam1, WarpedCam3, WarpedCam4]), axis = 0)       #choose between mean and median\n",
    "        ssd_greater = np.greater(ssd_Scores,ssd_opt)\n",
    "        ssd_opt = np.where(ssd_greater, ssd_Scores, ssd_opt)\n",
    "        ReconstructCam2[:,:,0] = np.where(ssd_greater, warp_combined[:,:,0], ReconstructCam2[:,:,0])\n",
    "        ReconstructCam2[:,:,1] = np.where(ssd_greater, warp_combined[:,:,1], ReconstructCam2[:,:,1])\n",
    "        ReconstructCam2[:,:,2] = np.where(ssd_greater, warp_combined[:,:,2], ReconstructCam2[:,:,2])\n",
    "        cv.imwrite('./results/'+ settings['dataset'] + '/synthesis'+ \\\n",
    "               str(settings[\"patch_size\"]) + 'x' + str(settings[\"patch_size\"]) + 'mean' + '.jpg', ReconstructCam2)\n",
    "    \n",
    "\n",
    "    cv.inshow(warp_combined)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59c5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
